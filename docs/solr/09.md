# 九、附加功能

开发搜索引擎的目的是帮助用户以最方便的方式找到最相关的信息。在第 6 章和 [7](07.html) 中，您了解了检索文档的各种方法以及 Solr 提供的实现。

在本章中，您将了解 Solr 的其他重要特性，这些特性将带来便利并增加用户体验。您还将看到可以用来控制文档排名和向用户推荐其他感兴趣的文档的其他功能。

本章涵盖以下主题:

*   赞助搜索
*   拼写检查
*   自我暗示
*   文档相似度

## 赞助搜索

对于给定的查询，您可能希望将一组精选的文档提升到搜索结果的顶部。你通常需要这样一个特性，要么允许赞助搜索，要么支持编辑提升。Google AdWords 是赞助搜索的一个典型例子。此外，有时一个相关的文档可能在响应中排名靠后，或者一个不相关的文档可能排名靠后，您将需要一个快速的解决方案来修复这些问题，尤其是当它们在生产中被发现时。

Solr 提供了`QueryElevationComponent`作为快速简单的解决方案来满足这些需求。对于指定的查询，它支持以下行为，而不考虑文档的分数:

*   将所需的一组文档置于搜索结果的顶部
*   从搜索结果中排除一组文档

Note

`QueryElevationComponent`要求在`schema.xml`中定义`uniqueKey`字段。它也适用于分布式环境。

### 使用

以下是使用查询提升组件的步骤:

Define the elevation file. This file contains the rules for elevating and excluding documents. The filename must map to the name provided in the `config-file` parameter in `QueryElevationComponent`. The following is a sample query elevation file. elevate.xml `<elevate>` `<query text="dslr camera">`   `<doc id="101" />`   `<doc id="103" />` `</query>` `<query text="laptop">`    `<doc id="106" />`    `<doc id="108" exclude="true" />` `</query>` `</elevate>` The `text` attribute of the `query` element specifies the query to be editorially boosted. The `doc` element represents the documents to be manipulated. Its `id` attribute marks the document that should be elevated, and if the additional attribute `exclude="true"` is specified, the document is marked for exclusion. The provided `id` should map to the `uniqueKey` of a document. The elevation file must exist either in the `$SOLR_HOME/<core>/conf/` or `$SOLR_HOME/<core>/data` directory. If it exists in `conf`, modifications to the file will reflect on core reload; and if it exists in `data`, modifications will reflect for each `IndexReader`. Note The component first looks for `elevate.xml` in the `conf` directory (or ZooKeeper, if applicable) and then in `data`. If you have the file in both directories, `conf` will get the priority.   Configure the `QueryElevationComponent` in `solrconfig.xml`. Table [9-1](#Tab1) describes the arguments supported to control the behavior of the component. The following is an example configuration.

表 9-1。

QueryElevationComponent Parameters

<colgroup><col> <col></colgroup> 
| 参数 | 描述 |
| --- | --- |
| `config-file` | 指定包含查询提升规则的文件的名称。 |
| `queryFieldType` | 指定应该用于分析用户查询的`fieldType`。分析的术语与提升文件中定义的查询相匹配。指定的`fieldType`必须存在于`schema.xml`中。如果不想进行分析，将`string`指定为`queryFieldType`。 |
| `forceElevation` | 查询提升根据配置从结果集中引入或删除文档，但考虑排序。如果应用除`score desc`之外的任何排序，提升的文档将根据排序条件改变它们的顺序。将该参数设置为`true`会覆盖该行为。 |
| `editorialMarkerFieldName` | 该参数有助于区分提升的文档和有机排序的文档。提升的文档获得一个具有此名称的附加字段。默认名称是`editorial`。当分配的名称被添加到`fl`请求参数时，标记被启用。进一步提供了使用这种标记的例子。 |
| `markExcludes` | 默认情况下，排除的文档会从搜索结果中删除。将该参数设置为`true`会将此类文档标记为已排除，而不是将其全部删除。 |
| `excludeMarkerFieldName` | 此参数为排除的文档分配一个字段名。它仅适用于`markExcludes`参数。分配的默认名称是`excluded`。 |

`<searchComponent name="elevator" class="solr.QueryElevationComponent" >` `<str name="config-file">elevate.xml</str>` `<str name="queryFieldType">string</str>` `</searchComponent>`   Register the component to the `last-``components` list of the desired handler. `<requestHandler name="/select" class="solr.SearchHandler">` `<lst name="defaults">` `<str name="echoParams">explicit</str>` `</lst>` `<arr name="last-components">` `<str>elevator</str>` `</arr>` `</requestHandler>`   Provide additional request parameters for the component. Table [9-2](#Tab2) lists the additional parameters supported.

表 9-2。

QueryElevationComponent Request Parameters

<colgroup><col> <col></colgroup> 
| 参数 | 描述 |
| --- | --- |
| `enableElevation` | 该参数启用`QueryElevationComponent`。 |
| `exclusive` | 如果启用此布尔参数，则仅返回提升的结果。有机结果将被忽略。 |
| `elevateIds` | 此参数指定要提升的文档 id 的逗号分隔列表。 |
| `excludeIds` | 此参数指定要排除的文档 id 的逗号分隔列表。 |

  Query for results. The following are some sample queries. Search request with QueryElevationComponent enabled `$ curl "` `http://localhost:8983/solr/hellosolr/select?q=laptop&enableElevation=true` `"` Search request that marks the elevated and excluded field `$ curl "` `http://localhost:8983/solr/hellosolr/select?q=laptop` `&markExcludes=true&fl=*,[elevated],[excluded]"` Search request to mark the elevated field, if editorialMarkerFieldName is specified as paid `$ curl "` `http://localhost:8983/solr/hellosolr/select?q=laptop` `&enableElevation=true&fl=*,[paid],score"` Search request that specifies the elevation and exclusion IDs `$ curl "` `http://localhost:8983/solr/hellosolr/select?q=cable` `&df=product&excludeIds=IW-02&elevateIds=3007WFP,9885A004"`  

## 拼写检查

用户查询容易出错，所以几乎所有流行的搜索引擎都支持拼写检查功能。对于拼写错误的查询，此功能会建议文本的正确形式。您通常会在搜索框的正下方看到建议。例如，去 Amazon.com 并搜索 laptap(laptop 的拼写错误形式),响应将包含额外的信息，如您的意思是:laptop。

搜索引擎采用两种方法进行拼写检查。他们要么执行原始查询并提供拼写建议，要么执行拼写纠正的查询，并选择运行原始查询。网络搜索引擎，如谷歌、必应和雅虎！采取乐观的拼写纠正方法。它们检索正确形式的查询的结果，并为用户提供执行原始查询的选项。

图 [9-1](#Fig1) 描述了一个典型的拼写检查示例(来自 Google ),其中拼写错误的查询 wikipedia 被纠正为 Wikipedia，并为其提供了一个结果。

![A978-1-4842-1070-3_9_Fig1_HTML.jpg](img/A978-1-4842-1070-3_9_Fig1_HTML.jpg)

图 9-1。

Example of spell-checking in Google

Solr 为拼写检查提供了现成的支持。它允许您根据 Solr 字段、外部 Lucene 索引或外部文本文件中维护的术语提供建议。Solr 提供了`SpellCheckComponent`，它扩展了`SearchComponent`来实现这个特性，并且可以配置到任何`SearchHandler`来让它工作。

如果你只是想给用户提供一个拼写建议，比如问“你的意思是？”，将`SpellCheckComponent`配置到查询处理程序，例如`/select`，并在适当的位置显示该组件的响应，以供用户操作。如果您的目的是向用户提供一个自动修正的结果，那么在一个单独的处理程序中配置`SpellCheckComponent`，比如`/spell`，并在启用排序的情况下进行查询。在本节的后面，您将了解到排序规则。客户端应该使用这个处理程序返回的拼写正确的响应向查询处理程序发出新的请求，比如`/select`。这个自动纠正过程需要两个 Solr 请求。

`SpellCheckComponent`提供了一组拼写检查的可选选项，可在`classname`参数中指定。可以将多个拼写检查器配置为同时执行。

您应该对用于拼写检查的字段执行最少的分析。应该避免将标记转换为完全不同的形式的分析，例如词干分析或同义词扩展。对于基于 Solr 字段的拼写检查器，最好有一个单独的字段用于拼写检查，所有需要拼写建议的字段的内容都可以复制到这个字段中。

`SpellCheckComponent`支持分布式环境。

### 通用参数

表 [9-3](#Tab3) 指的是通用参数，可以在任何拼写检查器实现中使用。

表 9-3。

SpellCheckComponent Generic Parameters

<colgroup><col> <col></colgroup> 
| 参数 | 描述 |
| --- | --- |
| `name` | 为拼写检查定义指定一个名称。在为组件配置多个拼写检查器时，此参数非常有用。 |
| `classname` | 指定要使用的拼写检查器实现。值可以指定为`solr.<implementation-class>`，比如`solr.FileBasedSpellCheck`。默认实现是`IndexBasedSpellCheck`。 |

### 履行

本节解释 Solr 中可用的拼写检查器实现。每个都提供了一组特定参数，可与表 [9-3](#Tab3) 中的通用参数一起使用。

#### IndexBasedSpellChecker

使用单独的索引来维护拼写检查词典。该索引是一个附加索引，也称为副索引，它是与主索引分开创建和维护的。在配置拼写检查器时，您可以指定用于创建 sidecar 索引的源字段。

这是在`SpellCheckComponent`中注册的默认拼写检查器实现。

表 [9-4](#Tab4) 规定了配置`IndexBasedSpellChecker`的附加参数。

表 9-4。

IndexBasedSpellChecker Parameters

<colgroup><col> <col></colgroup> 
| 参数 | 描述 |
| --- | --- |
| `field` | 指定 Solr 字段，在`schema.xml`中定义，用于构建字典。 |
| `sourceLocation` | 这个拼写检查器不从 Solr 字段加载术语，而是允许您从任意 Lucene 索引中加载术语。该参数指定 Lucene 索引的目录。 |
| `spellcheckIndexDir` | 指定将创建边车索引的目录。 |
| `buildOnCommit` | 将这个布尔参数设置为`true`会在每次提交时构建字典。默认情况下，该参数设置为`false`。 |

#### DirectSolrSpellChecker

这个实现使用主 Solr 索引，而不是专门为拼写检查构建额外的索引。因为使用了主索引，拼写检查器总是有最新的可用术语，并且还可以省去您定期重建索引的麻烦。

表 [9-5](#Tab5) 规定了配置`DirectSolrSpellChecker`的附加参数。

表 9-5。

DirectSolrSpellChecker Parameters

<colgroup><col> <col></colgroup> 
| 参数 | 描述 |
| --- | --- |
| `field` | 指定 Solr 字段，在`schema.xml`中定义，用于拼写检查。 |
| `accuracy` | 指定建议的准确性级别。默认值为 0.5。 |
| `maxEdits` | 指定术语中允许的最大修改次数。 |
| `minPrefix` | 指定允许编辑的最小初始字符数。值越高，性能越好。此外，您会注意到前几个字符通常不会拼写错误。默认值为 1。 |
| `maxInspections` | 指定在返回建议之前要检查的最大匹配数。默认值为 5。 |
| `minQueryLength` | 指定查询中用于生成建议的最小字符数。如果查询短于此长度，将不会生成任何建议。 |
| `maxQueryFrequency` | 指定查询词应该出现在文档中的最大数量。如果计数大于指定的阈值，该项将被忽略。该值可以是绝对值(例如 5)或百分比(例如 0.01 或 1%)。默认值为 0.01。 |
| `thresholdTokenFrequency` | 指定查询词应该出现在文档中的最小数量。如果计数小于指定的阈值，该项将被忽略。与`maxQueryFrequency`类似，可以指定绝对值或百分比。默认值为 0.0。 |

#### FileBasedSpellChecker

使用一个外部文本文件作为拼写的来源，并用它构建一个 Lucene 索引。当您不希望拼写检查器基于索引文档中的术语，而是从另一个来源(如频繁查询的日志分析或外部主题词表)提取时，这种实现很有帮助。

源文件应该是一个简单的文本文件，每行定义一个单词。这是一个样本文件。

medical-spellings.txt

`advanced`

`aided`

`assigned`

`assessed`

`assisted`

`..`

表 [9-6](#Tab6) 规定了配置`FileBasedSpellChecker`的附加参数。

表 9-6。

FileBasedSpellChecker Parameters

<colgroup><col> <col></colgroup> 
| 参数 | 描述 |
| --- | --- |
| `sourceLocation` | 指定包含术语的文本文件的路径。 |
| `characterEncoding` | 指定文件中术语的编码。 |
| `spellcheckIndexDir` | 指定将创建索引的目录。 |

#### WordBreakSolrSpellChecker

该实现侧重于执行拼写检查，以检测由于缺少或不需要的空白而导致的拼写错误。用户很可能会将一个单词拆分成两个单词，或者将两个单词合并成一个单词。一个典型的例子是拼写检查和拼写检查。`WordBreakSolrSpellChecker`就是为了解决这个特殊问题而开发的。它组合和分解术语来提供建议。

表 [9-7](#Tab7) 规定了配置`WordBreakSolrSpellChecker`的附加参数。

表 9-7。

WordBreakSolrSpellChecker Parameters

<colgroup><col> <col></colgroup> 
| 参数 | 描述 |
| --- | --- |
| `field` | 指定 Solr 字段，在`schema.xml`中定义，用于构建字典。 |
| `combineWords` | 指定是否应该合并相邻的术语。默认值为`true`。 |
| `breakWords` | 指定拼写检查器是否应该尝试将术语拆分为多个术语。默认值为`true`。 |
| `maxChanges` | 指定拼写检查器应该进行的最大排序尝试次数。 |

### 它是如何工作的

Solr 中的`SpellCheckComponent`类实现了`SearchComponent`，它利用了 Lucene 提供的`SpellChecker`实现。`SpellCheckComponent`处理请求的步骤如下:

The client makes a request to a `SearchHandler` that has `SpellCheckComponent` registered to it.   The `SpellCheckComponent`, like any other `SearchComponent`, executes in two phases, namely prepare and process.   If the received request is to build or reload the dictionary, it is done in the prepare phase. `DirectSolrSpellChecker` and `WordBreakSolrSpellChecker` don’t require a build or reload.   In the process phase, Solr tokenizes the query with the applicable query analyzer and calls the appropriate `SpellChecker` with the provided request parameters.   The spell-checker implementation generates suggestions from the loaded dictionary or field as applicable.   If collation is required, Solr calls the `SpellCheckCollator` to collate the spellings.   The generated responses are returned to the client.   Note

如果您对内部处理的细节感兴趣或者正在计划定制，可以参考这些步骤；否则 Solr 不要求你了解他们。

### 使用

下面是集成和使用拼写检查器的步骤:

Define the `SpellCheckComponent` in `solrconfig.xml`, specify the implementation classname, and add the parameters from the table of corresponding classnames. Register a single spell-checker `<searchComponent name="spellcheck" class="solr.SpellCheckComponent">` `<lst name="spellchecker">` `<str name="classname">solr.IndexBasedSpellChecker</str>` `<str name="spellcheckIndexDir">./spellchecker</str>` `<str name="field">spellings</str>` `<str name="buildOnCommit">true</str>` `</lst>` `</searchComponent>` Register multiple spell-checkers `<searchComponent name="spellcheck" class="solr.SpellCheckComponent">` `<lst name="spellchecker">` `<str name="name">primary</str>` `<str name="classname">solr.IndexBasedSpellChecker</str>`     `..` `</lst>` `<lst name="spellchecker">` `<str name="name">secondary</str>` `<str name="classname">solr.FileBasedSpellChecker</str>`     `..` `</lst>` `</searchComponent>`   Register the component to the desired `SearchHandler`. You can register it either to your primary handler that serves the search request or a separate handler dedicated for spell-checking. The following is an example configuration that registers multiple spell-checkers to the `/select` handler. `<requestHandler name="/select" class="solr.SearchHandler">` `<lst name="defaults">` `<str name="spellcheck.dictionary">primary</str>` `<str name="spellcheck.dictionary">secondary</str>` `</lst>` `<arr name="last-components">` `<str>spellcheck</str>` `</arr>` `</requestHandler>` Table [9-8](#Tab8) lists the request parameters supported by `SpellCheckComponent`.

表 9-8。

SpellCheckerComponent Request Parameters

<colgroup><col> <col></colgroup> 
| 参数 | 描述 |
| --- | --- |
| `spellcheck` | 默认情况下，拼写检查是禁用的。设置`spellcheck="true"`打开该功能。 |
| `spellcheck.q` | 指定拼写检查的查询。如果未指定该参数，组件将从`q`参数中获取值。 |
| `spellcheck.count` | 指定要返回的建议的最大数量。默认值为 1。 |
| `spellcheck.dictionary` | 指定用于请求的词典。 |
| `spellcheck.build` | 此参数清除现有字典，并使用源中的最新内容创建一个新副本。此操作的成本可能很高，应该偶尔触发。 |
| `spellcheck.reload` | 将该参数设置为`true`会重新加载拼写检查器和底层词典。 |
| `spellcheck.accuracy` | 以浮点值的形式指定所需的精度级别。分数低于此值的建议将不会提供。 |
| `spellcheck.alternativeTermCount` | 指定为每个查询词返回的建议数。这有助于构建上下文相关的拼写纠正。 |
| `spellcheck.collate` | 如果有多个建议，或者您想向用户提供拼写正确的查询结果，那么将该参数设置为`true`是一个不错的选择。该特性为查询中的每个标记提取最佳建议，并将它们组合成一个新的查询，您可以执行该查询以获得建议的结果。 |
| `spellcheck.maxCollations` | 默认情况下，Solr 返回一个排序规则。您可以设置该参数来获取更多的排序规则。 |
| `spellcheck.maxCollationTries` | 排序规则的功能确保排序查询在索引中找到匹配项。该特性指定了对索引进行测试的次数。在测试时，原始查询被排序规则替代，并尝试进行匹配。默认值 0 可以跳过测试，从而导致不匹配。较高的值可以确保更好的排序，但代价会很高。 |
| `spellcheck.maxCollationEvaluations` | 指定要评估和排序的最大组合数，以形成对索引进行测试的排序规则。默认值已被优化设置为 10，000 个组合。 |
| `spellcheck.collateExtendedResult` | 将该参数设置为`true`将扩展响应，以包含排序规则的详细信息。 |
| `spellcheck.collateMaxCollectDocs` | 测试排序规则时，如果不需要命中次数，此参数有助于提高性能。对于值 0，通过对所有文档运行测试来提取准确的命中次数。对于大于 0 的值，基于那些文档提供估计。 |
| `spellcheck.collateParam.*` | 您可以使用此前缀来覆盖默认的查询参数，或者为归类测试查询提供一个附加的查询参数。通过在`spellcheck.collateParam.fq`中指定覆盖值，可以覆盖所有的`fq`参数。 |
| `spellcheck.extendedResults` | 此布尔参数指定是否使用包含更多详细信息的扩展响应格式。扩展响应格式不同于标准建议；对于每个建议，它提供了文档频率，对于每个术语，它提供了一个包含附加信息(如术语频率)的建议块，默认值为`false`。 |
| `spellcheck.onlyMorePopular` | 如果该参数设置为`true`，则仅当建议的标记比原始术语具有更高的文档频率时，才返回建议。默认情况下，该参数设置为`false`。 |
| `spellcheck.maxResultsForSuggest` | 默认情况下，`correctlySpelled`响应参数被设置为`false`，只有当查询术语在字典和索引中都缺失时，才会返回建议。如果索引的结果达到指定的数量，则将该参数设置为大于 0 的值将返回一个建议。例如，如果响应最多有 9 个结果，值 10 将返回建议，如果有 10 个或更多结果，则不返回建议。 |

  Query for search results with the spell-checking feature enabled.   Builds the spell-checker and then generates a spelling suggestion

`$ curl "` `http://localhost:8983/solr/hellosolr/select?q=wikipadia`

`&spellcheck=true&spellcheck.build=true"`

任何拼写建议的请求只有在词典建立后才会得到结果。因此，在请求拼写建议之前，`spellcheck.build=true`应该至少被触发一次。构建操作可能成本很高，应该不经常触发。

Request suggestions for the user query

`$ curl "` `http://localhost:8983/solr/hellosolr/select?q=wikipadia`

`&spellcheck=true&spellcheck.count=5&spellcheck.accuracy=0.6"`

## 自动完成

自动完成是用户搜索体验的一个重要特性。这是一种预输入搜索，只要用户输入几个字符，它就会完成单词或预测其余的单词。对于用户键入的每个额外字符，建议被细化。大多数现代搜索引擎都支持这个特性。

以下是实现自动完成的一些主要原因:

*   实现自动完成最简单的原因是为了避免拼写错误。如果所提供的建议是正确的，并且用户选择了它，则查询将没有拼写错误。
*   如果预测是正确的，用户就不需要键入完整的查询。用户可以选择其中一个建议，然后按回车键。
*   有时用户知道他们想要什么，但不知道如何用语言表达。当一个搜索关键字有许多常见的同义词，或者您正在寻找某个问题的答案时，您可能会遇到这种情况。Google autocomplete 在这方面做得很好，如果弹出一个建议，您可以相当自信地认为您正在制定一个正确的查询。
*   自动完成有助于查询分类和应用过滤器。在电子商务中，建议根据产品的主要方面对产品进行分类。例如，查询 jeans 可能会给出诸如 jeans(男士)或 jeans(女士)的建议，而查询 apple 可能会给出诸如 apple(手机)或 apple(笔记本电脑)的建议。
*   该功能还用于根据查询生成建议。它再次广泛应用于电子商务，根据查询向用户推荐最畅销的产品。例如，只要你输入尼康，自动完成功能就会显示像尼康 3200 这样的畅销产品及其价格，甚至可能还有一张图片。

自我暗示可以有多种类型，也可以基于多种来源。提供给用户的建议可以是完整的短语或特定的单词。短语可以从 Solr 索引或用户日志中提取。如果搜索引擎被广泛使用并拥有大量用户，从日志中提取的短语可以产生更实际的建议。来自日志的查询应该经过一系列的处理，比如过滤掉索引中没有匹配的查询；有拼写错误的查询应该被过滤掉或进行拼写纠正；网络搜索引擎会先过滤掉对敏感话题和不良内容的查询，然后再生成短语。在建议之前应该折叠短语，以便不会多次建议相同或相似的短语。

短语建议可以与令牌建议等其他方法结合使用，令牌建议可以作为一种后备机制。当没有短语建议可用于用户键入的查询时，系统可以完成用户正在键入的单词。

Solr 提供了多种供应和实现来实现自动补全。每一种都有其优点和局限性。您选择哪一种或哪几种组合取决于您的需求。由于为用户按下的每个键都提供了一个建议，所以无论您采用哪种方法都不应该忽略性能，并且应该快速生成建议。Solr 提供的实现可以大致分为两类:

*   传统方法:这种方法利用 Solr 的现有分析器和组件来获得特性。
*   SuggestionComponent:专门为支持自动完成功能而开发的组件。

### 传统方法

传统的自动建议方法指的是 Solr 版之前引入的条款。在这种方法中，自动完成是通过利用 Solr 中已经可用的特性来实现的。您所需要做的就是对它进行适当的配置，让它正常工作。

在这种方法中，应该根据您想要生成的建议类型，在现场配置适当的分析器。对于暗示短语，`KeywordTokenizerFactory`是合适的；而对于暗示的话，`StandardTokenizerFactory`或者`WhitespaceTokenizerFactory`是合适的。您可以两者都用，给短语字段更高的权重。

用于生成建议的字段应该分析为小写，以执行不区分大小写的搜索。一些组件(接下来将详细讨论)不支持查询时分析，在这种情况下，客户端程序可能需要将查询转换成小写形式。任何其他处理都可以在索引时分析中进行，以便适当地匹配标记。

以下是实现自我暗示的传统方法。

#### 术语组件

`TermsComponent`提供对字段中索引的术语的直接访问，并返回包含该术语的文档数。该组件直接访问 Lucene 术语词典，因此检索速度很快。

##### 利益

以下是使用`TermsComponent`进行自动暗示的好处:

*   直接查找术语词典，因此是所有传统自我暗示方法中最快的。
*   它允许您执行前缀和中缀查询。

##### 限制

以下是这种方法的局限性:

*   `TermsComponent`直接查找术语词典，因此不能应用过滤器将结果限制在文档的子集内。例如，您不能只检索库存产品。
*   直接查找的另一个限制是，它还会考虑标记为删除的术语。
*   `TermsComponent`不分析查询。

##### 使用

以下是为自动建议配置`TermsComponent`的步骤:

Define the `TermsComponent` in `solrconfig.xml`. `<searchComponent name="terms" class="solr.TermsComponent"/>`   Register the component to the desired request handler. `<requestHandler name="/terms" class="solr.SearchHandler" startup="lazy">` `<lst name="defaults">` `<bool name="distrib">true</bool>` `</lst>` `<arr name="components">` `<str>terms</str>` `</arr>` `</requestHandler>` Table [9-9](#Tab9) defines the important parameters of `TermsComponent` for supporting autocomplete.

表 9-9。

TermsComponent Important Request Parameters

<colgroup><col> <col></colgroup> 
| 参数 | 描述 |
| --- | --- |
| `terms` | 指定`terms="true"`启用`TermsComponent`。默认情况下，该组件处于禁用状态。 |
| `terms.fl` | 指定应该从中检索术语的字段名称。 |
| `terms.limit` | 指定要检索的最大术语数。 |
| `terms.prefix` | 在此参数中指定用户键入的查询，以检索以该查询开头的所有标记。 |
| `terms.regex` | 指定用于检索术语的正则表达式模式。这对中缀自动补全很有用。该操作的执行成本可能比`terms.prefix`高，但允许中缀操作。在请求处理程序之前，用户查询需要预处理来形成正则表达式。 |
| `terms.regex.flag` | 指定`terms.regex.flag=case_insensitive`执行不区分大小写的正则表达式。 |
| `terms.mincount` | 响应中将不会返回文档频率小于指定值的术语。此参数可用于避免拼写错误的内容，假设它们出现的频率很低。 |
| `terms.maxcount` | 文档频率超过指定值的术语将不会在响应中返回。此参数有助于消除可能成为停用词的术语。 |
| `terms.sort` | 指定`terms.sort=count`首先对出现频率最高的术语进行排序，指定`terms.sort=index`按索引顺序进行排序。 |

  No specific text analysis is required on the `fieldType`. You may just want to convert all tokens to lowercase for case-insensitive matching. A typical `fieldType` is defined as follows: `<fieldType name="autocomplete" class="solr.TextField" positionIncrementGap="100" >`   `<analyzer type="index">` `<tokenizer class="solr.KeywordTokenizerFactory"/>` `<filter class="solr.LowerCaseFilterFactory"/>` `</analyzer>` `<analyzer type="query">` `<tokenizer class="solr.KeywordTokenizerFactory"/>` `<filter class="solr.LowerCaseFilterFactory"/>` `</analyzer>` `</fieldType>`   Define the field for autosuggestion. The field need not be stored. `<field name="brand" type="autocomplete" indexed="true" stored="false" />`   Send a request for each character typed by the user.   Suggest all terms beginning with specified characters

`$ curl "` `http://localhost:8983/solr/hellosolr/terms?terms=true&terms.fl=brand"`

Suggest all terms containing the specified characters

`$ curl "` `http://localhost:8983/solr/hellosolr/terms?terms=true&terms.fl=brand`

`&terms.regex=.*eebo.*&terms.regex.flag=case_insensitive&terms.limit=5"`

#### 面状

分面可以用来实现自我暗示。这有利于在`category`等字段上生成建议。方面也将计数与术语一起返回。第 7 章提供了刻面的细节。

##### 利益

以下是使用`FacetComponent`进行自动建议的好处:

*   它允许您过滤要在文档子集上运行的建议。例如，您可以只检索有库存的产品。

##### 限制

以下是这种方法的局限性:

*   分面是一个占用大量内存的过程，尤其是在唯一令牌的数量很大的情况下。与`TermsComponent`相比，它的响应时间也很长。
*   它不支持检索中缀项。
*   它不分析查询。

##### 使用

默认情况下，`FacetComponent`对处理程序可用，不需要注册。以下是使用分面配置自动建议的步骤:

Define the `fieldType` for text analysis of the faceted field. `<fieldType name="autocomplete" class="solr.TextField" positionIncrementGap="100" >` `<analyzer type="index">` `<tokenizer class="solr.KeywordTokenizerFactory"/>` `<filter class="solr.LowerCaseFilterFactory"/>` `</analyzer>` `<analyzer type="query">` `<tokenizer class="solr.KeywordTokenizerFactory"/>` `<filter class="solr.LowerCaseFilterFactory"/>` `</analyzer>` `</fieldType>`   Define the field for autosuggestion. The field need not be stored. `<field name="autocomplete" type="autocomplete" indexed="true" stored="false" />`   Leverage the `facet.prefix` request parameter provided by faceting for generating a suggestion. The value supplied to this parameter is not analyzed, so as a convention always lowercase the value before supplying it to the field.   Generate a suggestion using the facet.prefix feature of FacetComponent

`$ curl "``http://localhost:8983/solr/hellosolr/select?q`T2】

`&rows=0&facet=true&facet.field=brand&facet.mincount=5`

`&facet.limit=5&facet.prefix=ree"`

表 [9-10](#Tab10) 描述了`FacetComponent`支持自动建议的重要参数。

表 9-10。

FacetComponent Parameters for Autosuggestion

<colgroup><col> <col></colgroup> 
| 参数 | 描述 |
| --- | --- |
| `facet` | 指定`facet=true`启用`FacetComponent`。 |
| `rows` | 设置`rows=0`，因为你不需要从 Solr 获取搜索结果。 |
| `facet.prefix` | 指定用户查询以检索以它开头的所有建议。 |
| `facet.field` | 指定应在其上执行刻面的字段。 |
| `facet.mincount` | 此参数可用于避免拼写错误的内容，假设对计数小于阈值的术语不感兴趣。 |
| `facete.limit` | 此参数限制生成的建议数量。 |

#### EdgeNGram

我们在[第 4 章](04.html)中讨论模式设计时讨论了`NGram`。`EdgeNGram`从一条边开始，将记号分解成不同大小的子记号。对于 autocomplete，只对从前端创建的标记感兴趣。

##### 利益

以下是使用`EdgeNGram`进行自动暗示的好处:

*   当您需要搜索整个文档而不仅仅是拼写建议时,`EdgeNGram`对于生成建议非常有用。电子商务中的一个典型例子是向用户推荐受欢迎的产品，在这种情况下，您还需要返回产品的图片和价格。
*   它允许您将结果限制在文档的子集内。例如，您可以只检索库存产品。
*   可以提升文档，例如，如果您希望热门的匹配文档在建议列表中排名更高。
*   可以执行查询时分析。

##### 限制

以下是这种方法的局限性:

*   这种方法会生成许多令牌，从而增加索引的大小。
*   可能会有性能问题，缓慢的提前键入违背了自动完成的目的。
*   搜索查询在`EdgeNGram`字段上执行，响应可以包含重复的标记。因此，多个文档的建议字段不应具有相同的值。如果您不能删除多余的文档，您需要使用一种混合的方法，即`EdgeNGram`和刻面。`EdgeNGram`可以在用户查询日志中创建一个单独的索引来生成建议时发挥作用。

##### 使用

以下是使用`EdgeNGram`配置自动建议的步骤:

Define a `fieldType` to use `EdgeNGram`. `<fieldType name="edgengram" class="solr.TextField" positionIncrementGap="100"` `omitNorms="true" omitTermFreqAndPositions="true">` `<analyzer type="index">` `<tokenizer class="solr.KeywordTokenizerFactory"/>` `<filter class="solr.LowerCaseFilterFactory"/>` `<filter class="solr.EdgeNGramFilterFactory" minGramSize="3" maxGramSize="15" />`   `</analyzer>` `<analyzer type="query">` `<tokenizer class="solr.KeywordTokenizerFactory"/>` `<filter class="solr.LowerCaseFilterFactory"/>` `</analyzer>` `</fieldType>` Set the attribute `minGramSize` to specify the minimum characters from which suggestions should start coming up. Specify the attribute `maxGramSize` to specify the characters beyond which you don’t want to provide any refinement. The `EdgeNGramFilterFactory` should be applied only at index time. In the preceding `fieldType` text analysis, you have defined `EdgeNGramFilterFactory` to generate grams from a minimum size of 3 to a maximum size of 15.   Define the field for generating suggestions. `<field name="autocomplete" type="edgengram" indexed="true" stored="true" />`   Execute the query to generate suggestions. `$ curl "` `http://localhost:8983/solr/hellosolr/select?q=autocomplete:lapt` `"`  

### 建议组件

Solr 3.1 引入了一个专门的组件来解决自动建议的问题。这种方法使用 Lucene 的 suggester 模块，比前面讨论的方法更加强大和灵活。

`SuggestComponent`的两个重要方面是字典和查找算法。在配置建议器时，您需要选择两者的实现。接下来将描述这两个方面。

#### 词典

字典指定了维护术语的来源。Solr 提供的实现使用了`Dictionary`接口。概括地说，词典可以有以下两种类型:

*   基于索引:使用 Lucene 索引作为生成建议的来源
*   基于文件:使用指定位置的文本文件来生成建议

以下是 Solr 提供的实现。

##### 文档字典工厂

`DocumentDictionaryFactory`是一个基于索引的字典，使用术语、权重和可选的有效负载来生成建议。以下是此实现支持的附加参数。

*   `weightField`:如果要给术语分配权重，在此参数中指定包含权重的字段名。分配的默认权重为 0。该字段应该被存储。
*   `payloadField`:如果你想给术语分配一个有效载荷，在此参数中指定包含有效载荷的字段名。该字段应该被存储。

##### DocumentExpressionDictionaryFactory

这个工厂提供了一个`DocumentValueSourceDictionary`的实现，它扩展了`DocumentDictionary`来支持一个权重表达式，而不是一个数字权重。

以下是此实现支持的附加参数:

*   `weightExpression`:您可以指定一个表达式来计算术语的权重。它使用 Lucene 表达式模块来计算表达式。表达式定义类似于函数查询表达式。例如，`"((div(rating,10) + 1) + sqrt(popularity))`"就是一个有效的表达式。表达式中指定的字段应为数字。该参数是必需的。
*   `payloadField`:如果你想给术语分配一个有效载荷，在此参数中指定包含有效载荷的字段名。必须存储该字段。

##### 高频词典

这是基于索引的字典的默认实现，它允许您只考虑构建字典的常用术语。频率小于阈值的项被丢弃。

以下是此实现支持的附加参数:

*   `threshold`:该参数指定添加到字典中的术语的阈值。该值可以在 0 和 1 之间，表示该术语应该出现在文档中的比例。该参数是可选的。如果未指定，则考虑所有术语。

##### FileDictionaryFactory

这是唯一支持的基于文件的字典实现，它允许您从外部文件读取建议。类似于基于索引的字典，权重和有效负载是允许的，可以在由分隔符分隔的术语后指定。

以下是此实现支持的附加参数:

*   `fieldDelimiter`:指定分隔条款、重量和有效载荷的分隔符。默认值为 tab。

这里是一个维护建议的样本文件。

suggestions.txt

`# File based suggestions`

`mobile\t1.0`

`mobile phone\t3.0`

`mobile cases\t2.0`

#### 算法

在选择了合适的字典实现之后，您需要选择最适合您的用例的`lookupImpl`。Lucene 支持一组算法(或数据结构),并为它们提供不同的实现。所有的实现类都扩展了`Lookup`抽象类。

以下是支持的数据结构的广泛定义:

*   有限状态转换器(FST):建议者用所有的术语建立一个自动机，用来满足所有的自动建议请求。
*   自动机提供快速搜索，内存占用低，但在所有支持的数据结构中，构建自动机的过程是最慢的。此外，术语不能附加到自动机。对于添加术语，应该从头开始构建。自动机可以作为二进制 blob 保存到磁盘上，以便在 Solr 重启或内核重载时快速重载。
*   三元搜索树(TST):三元搜索树类似于二叉查找树，但是最多可以有三个子树。它为术语查找提供了一种快速灵活的方法。该树可以动态更新。
*   JaSpell 算法:该算法由 Bruno Martins 编写，使用三叉树来提供高度复杂的建议。它可以快速构建数据结构。它支持基于 Levenshtein 距离的模糊查找，比 FST 更复杂。参考 Jaspell 网站 [`http://jaspell.sourceforge.net/`](http://jaspell.sourceforge.net/) 。
*   这些建议可以按字母顺序或诸如评级、受欢迎程度等参数排序。
*   基于索引:这种方法使用 Lucene 索引进行查找。

以下是 Solr 为查找提供的实现。每一个都定义了自己的参数集来支持所提供的功能。

##### TSTLookupFactory

该实现提供了基于三元搜索树的查找。它的建议者不支持有效负载，也不需要指定任何额外的参数。

##### FSTLookupFactory

这种实现提供了基于自动机的查找，速度非常快。这是一个很好的建议，除非你需要一个更复杂的。表 [9-11](#Tab11) 指定了`FSTLookupFactory`支持的参数。

表 9-11。

FSTLookupFactory Parameters

<colgroup><col> <col></colgroup> 
| 参数 | 描述 |
| --- | --- |
| `weightBuckets` | 指定为权重创建的桶数。计数可以在 1 到 255 之间。默认桶数是 10。 |
| `exactMatchFirst` | 如果设置为`true`，则首先返回准确的建议，而不考虑自动机中可用的其他字符串的前缀。 |

##### WFSTLookupFactory

这种实现基于加权 FST 算法。它使用最短路径方法来查找最佳建议。它支持`exactMatchFirst`参数。表 [9-11](#Tab11) 提供了关于该参数的信息。

##### JaspellLookupFactory

该实现基于 JaSpell 算法。它的执行速度很快，对许多问题都很有用。

##### 分析工厂

这种实现使用加权 FST 进行查找。它被称为`AnalyzingLookupFactory`,因为它在构建 FST 之前和查找期间分析文本。查找之前的分析提供了强大而灵活的自我暗示。分析链可以配置为使用停用词和同义词扩展等功能。例如，如果将 cell phone 和 mobile phone 定义为同义词，则用户文本单元格可以提供手机壳等建议。

分析器应该仔细配置，因为像停用词这样的特性可能导致没有建议。此外，返回的建议是原始文本，而不是文本的分析形式。表 [9-12](#Tab12) 指定了`AnalyzingLookupFactory`支持的参数。

表 9-12。

AnalyzingLookupFactory Parameters

<colgroup><col> <col></colgroup> 
| 财产 | 描述 |
| --- | --- |
| `suggestAnalyzerFieldType` | 指定用于分析的`fieldType`。 |
| `exactMatchFirst` | 如果设置为`true`，精确匹配将作为首选建议返回，而不考虑其他具有更高权重的建议。默认设置为`true`。 |
| `preserveSep` | 如果设置为`true`，则保留标记分隔符(即`cellphone`和`cell phone`不同)。默认设置为`true`。 |
| `preservePositionIncrements` | 如果设置为`true`，位置增量保持不变。如果设置为`false`，假设 of 是一个停用词，那么像`best 20`这样的用户查询将生成类似 2015 年最佳的建议。默认设置为`false’`。 |

##### 模糊 LookupFactory

`FuzzyLookupFactory`扩展了`AnalyzingLookup`的功能，允许基于 Levenshtein 距离对分析文本进行模糊匹配。它支持`AnalyzingLookupFactory`的所有参数，以及表 [9-13](#Tab13) 中提到的附加参数。

表 9-13。

FuzzyLookupFactory Parameters

<colgroup><col> <col></colgroup> 
| 财产 | 描述 |
| --- | --- |
| `maxEdits` | 指定允许的最大编辑次数。默认值为 1。该值的硬限制被指定为 2。 |
| `transpositions` | 如果`true`，将使用图元编辑操作计算变调。如果`false`，将使用 Levenshtein 算法。 |
| `nonFuzzyPrefix` | 指定查找键的长度，超过该长度的字符将执行模糊匹配。应该只建议包含键的初始前缀字符的匹配。默认值为 1。 |
| `minFuzzyLength` | 指定长度，在该长度以下将不对查找关键字执行编辑。默认值为 3。 |
| `unicodeAware` | 默认情况下，该参数设置为`false`，前面四个参数以字节为单位。如果该参数设置为`true`，它们将以实际字符进行测量。 |

##### 分析 gInfixLookupFactory

使用 Lucene 索引作为字典，并对索引的术语提供灵活的基于前缀的建议。与`AnalyzingLookupFactory`类似，它也在构建字典和查找时分析输入文本。表 [9-14](#Tab14) 指定了`AnalyzingInfixLookupFactory`支持的参数。

表 9-14。

AnalyzingInfixLookupFactory Parameters

<colgroup><col> <col></colgroup> 
| 参数 | 定义 |
| --- | --- |
| `indexPath` | 指定存储和加载索引的目录。默认情况下，索引是在`data`目录中创建的。 |
| `allTermsRequired` | 如果`true`，在多项键上应用布尔运算符`AND`；否则，应用操作员`OR`。默认值为`true`。 |
| `minPrefixChars` | 指定从开始使用`prefixQuery`的最小字符数。n 元语法是为短于这个长度的前缀生成的，这提供了更快的查找速度，但增加了索引大小。默认值为 4。 |
| `highlight` | 如果`true`是默认值，则建议被突出显示。 |

##### BlendedInfixLookupFactory

这个实现是对`AnalyzingInfixLookupFactory`的扩展，它允许您对前缀匹配应用权重。它允许您根据第一个匹配单词的位置分配更多的权重。它支持`AnalyzingInfixLookupFactory`的所有参数，以及表 [9-15](#Tab15) 中提到的附加参数。

表 9-15。

BlendedInfixLookupFactory Parameters

<colgroup><col> <col></colgroup> 
| 参数 | 描述 |
| --- | --- |
| `blenderType` | 指定用于计算权重系数的搅拌机类型。以下是支持的搅拌机类型:`linear`:使用公式`weight×(1 - 0.10×position)`计算重量。它在开始时给予匹配更高的权重。这是默认的`blenderType`。`reciprocal`:使用公式`weight/(1+position)`计算重量。它最终会给匹配项更高的权重。 |
| `numFactors` | 指定结果数的倍增因子。默认值为 10。 |

##### FreeTextLookupFactory

当其他建议者找不到匹配时，这个建议者已经实现了回退建议的需求。它在构建词典时构建文本的 N 元语法，并在查找时考虑来自用户查询的最后 N 个单词。它适合处理以前从未见过的查询。表 [9-16](#Tab16) 指定了`FreeTextLookupFactory`支持的参数。

表 9-16。

FreeTextLookupFactory Parameters

<colgroup><col> <col></colgroup> 
| 参数 | 描述 |
| --- | --- |
| `suggestFreeTextAnalyzerFieldType` | 指定用于分析的`fieldType`。此字段为必填字段。 |
| `ngrams` | 指定构建字典时要考虑的最后标记的数量。默认值为 2。 |

#### 它是如何工作的

Solr 中的自动建议特性由`SuggestComponent`提供，它与`SolrSuggester`交互以生成建议。以下是组件遵循的步骤:

The client makes a request to a `SearchHandler`, which has `SuggestComponent` registered to it.   The `SuggestComponent`, like any other `SearchComponent`, executes in two phases, namely prepare and process.   If the received request is to build or reload the dictionary, in the prepare phase the component calls the `SolrSuggester` to perform the task. `SolrSuggester` is responsible for loading the lookup and dictionary implementations specified in the configuration.   In the process phase, the component calls all the registered `SolrSuggesters` for getting the suggested results.   `SolrSuggestor` calls the appropriate implementation, which looks up a key and returns the possible completion for this key. Depending on the implementation, this may be a prefix, misspelling, or even infix.   The component converts the suggested results to an appropriate form and adds to the response.  

#### 使用

以下是在 Solr 中配置和使用`SuggestComponent`的步骤:

Define the `SuggestComponent` in `solrconfig.xml`. Table [9-17](#Tab17) specifies the parameters supported by the component.

表 9-17。

SuggestComponent Parameters

<colgroup><col> <col></colgroup> 
| 参数 | 描述 |
| --- | --- |
| `name` | 指定用于生成建议的建议者的名称。 |
| `dictionaryImpl` | 指定要使用的字典实现。默认情况下，`HighFrequencyDictionaryFactory`用于基于索引的数据结构，`FileDictionaryFactory`用于基于文件的数据结构。如果`sourceLocation`参数存在，组件假定使用基于文件的字典。 |
| `lookupImpl` | 指定要使用的查找实现。如果未提供该参数，默认情况下将使用`JaspellLookupFactory`。 |
| `field` | 对于基于索引的字典，此参数指定查找实现要使用的字段。 |
| `sourceLocation` | 如果使用`FileDictionaryFactory`，该参数指定字典文件路径。 |
| `storeDir` | 字典将被保存到的目录。 |
| `buildOnStartup` | 将这个布尔参数设置为`true`会在 Solr 启动和内核重载时构建数据结构。 |
| `buildOnCommit` | 将此布尔参数设置为`true`会在提交时构建数据结构。 |
| `buildOnOptimize` | 将此布尔参数设置为`true`会在优化时构建数据结构。 |

`<searchComponent name="suggest" class="solr.SuggestComponent">` `<lst name="suggester">`   `<str name="name">analyzedSuggestion</str>` `<str name="lookupImpl">AnalyzingLookupFactory</str>`   `<str name="dictionaryImpl">DocumentDictionaryFactory</str>`   `<str name="field">brand</str>`   `<str name="weightField">popularity</str>` `<str name="suggestAnalyzerFieldType">string</str>`   `<str name="buildOnStartup">false</str>` `</lst>` `</searchComponent>`   Register the component to the desired `SearchHandler`. Generally, if you like to have a dedicated endpoint for autosuggestion, add it to `components` instead of `last-components`. Table [9-18](#Tab18) specifies the parameters that can be configured in the handler or provided in the search request.

表 9-18。

SuggestComponent Parameters for the Request Handler

<colgroup><col> <col></colgroup> 
| 参数 | 描述 |
| --- | --- |
| `suggest` | 将该布尔参数设置为`true`会启用`SuggestComponent`。 |
| `suggest.q` | 应该检索其建议的用户查询。如果未指定该参数，组件将在`q`参数中寻找一个值。 |
| `suggest.dictionary` | 该参数是必需的。它指定用于生成建议的 suggester 组件的名称。 |
| `suggest.count` | 指定要检索的建议的最大数量。 |
| `suggest.build` | 将该参数设置为`true`构建建议者数据结构。构建操作的成本可能很高，因此可以根据需要触发该过程。表 [9-17](#Tab17) 提供了构建建议器的其他选项。 |
| `suggest.buildAll` | 将该参数设置为`true`为组件中注册的所有建议者建立数据结构。 |
| `suggest.reload` | 将该参数设置为`true`重新加载建议者数据结构。 |
| `suggest.reloadAll` | 将该参数设置为`true`重新加载组件中注册的所有建议者的数据结构。 |

`<requestHandler name="/suggest" class="solr.SearchHandler" startup="lazy">`   `<lst name="defaults">`     `<str name="suggest">true</str>`     `<str name="suggest.count">10</str>` `</lst>`   `<arr name="components">`     `<str>suggest</str>`   `</arr>` `</requestHandler>`   Define the `fieldType` for text analysis. `<fieldType class="solr.TextField" name="textSuggest"` `positionIncrementGap="100">`   `<analyzer>`     `<tokenizer class="solr.StandardTokenizerFactory"/>`     `<filter class="solr.StandardFilterFactory"/>`     `<filter class="solr.LowerCaseFilterFactory"/>`   `</analyzer>` `</fieldType>`   Define the field. The field must be set as `stored`. You might want to copy all the fields on which the suggestion should be generated to this field.   Query for results. If you are using a dedicated handler for suggestions, you can set `suggest=true` and other infrequently changing parameters in it, so that you don’t need to provide those parameters with each request. The following are the sample queries for generating suggestions.   Request to build specific suggester data structures

`$ curl "``http://localhost:8983/solr/hellosolr/suggest?suggest=true&suggest.buildAll=true`T2】

Request to build all the suggester data structures

`$ curl "` `http://localhost:8983/solr/hellosolr/suggest?suggest=true`

`&suggest.build=true&suggest.dictionary=analyzedSuggestion"`

Request for suggestions in the analyzedSuggestion dictionary

`$ curl "` `http://localhost:8983/solr/hellosolr/suggest?suggest=true`

`&suggest.dictionary=analyzedSuggestion&wt=json&suggest.q=lapt"`

## 文档相似度

开发搜索引擎的主要目的是检索与用户查询最相关的文档。一旦用户预览了检索到的文档，他很可能会对其他类似的文档感兴趣。如果应用程序是为搜索新闻、期刊和博客而开发的，那么建议相似的文档就变得更加重要。您可能对查找相似文档感兴趣的另一个领域是重复检测、剽窃和指纹识别。

Solr 提供了`MoreLikeThis`特性来解决查找相似文档的问题。这个特性也可以用于构建基于内容的推荐系统，这基本上是一个机器学习问题。基于内容的推荐系统使用项目特征或关键字来描述项目，这在 Solr 字段中已经可用。现在，如果您维护一个用户档案或从用户的购买历史和“喜欢”中提取产品的共同属性，您可以使用这些共同的关键字或属性查询`MoreLikeThis`来为用户生成推荐。

`MoreLikeThis`采用词袋方法进行相似性检测。它接受一个文档或任意文本作为输入，并返回匹配的文档。它允许您通过配置定义和请求参数来控制匹配功能。

`MoreLikeThis`中的相似文档检测是一个两阶段过程。以下是各阶段的处理细节:

*   检测感兴趣的关键字:该算法以统计方式确定文档中的重要和感兴趣的术语，以便检索相似的文档。它选择性地忽略非常常见、非常罕见、非常短或非常长的术语。如果 boost 使能，它们会添加到基于 TF-IDF 系数的项中。
*   匹配文档查询:第一阶段符合条件的术语作为搜索请求提交，检索最相关的文档。

### 先决条件

以下是使用`MoreLikeThis`组件的先决条件:

*   应当存储`uniqueKey`字段。
*   该组件中使用的字段应存储术语向量(`termVectors="true"`)。以下是示例字段定义:`<field name="product" type="text_general" indexed="true" stored="true" termVectors="true" />`
*   如果术语向量被禁用，则组件从存储的字段生成术语。因此，至少应该存储该字段(`stored="true"`)。

Caution

`MoreLikeThis`支持分布式搜索但是有一个公开的 bug [`https://issues.apache.org/jira/browse/SOLR-4414`](https://issues.apache.org/jira/browse/SOLR-4414) 。服务于请求的碎片应该包含文档；否则，`MoreLikeThis`不会找到任何匹配项。

### 履行

`MoreLikeThis`在 Solr 中有三种实现来满足不同的用户需求。实现如下所示:

*   `MoreLikeThisComponent`:可以注册到任何`SearchHandler`的组件列表中。如果您希望检索与主查询检索的每个文档相似的文档，这将非常有用。
*   `MoreLikeThisHandler`:这个处理程序允许您提供一个文档或内容流，并检索类似的文档。
*   `MLTQParserPlugin`:这个查询解析器通过使用文档 ID 和提供的其他统计信息形成一个`MoreLikeThisQuery`。

#### 通用参数

表 [9-19](#Tab19) 规定了适用于所有实现的通用参数。

表 9-19。

MoreLikeThis Generic Parameters

<colgroup><col> <col></colgroup> 
| 参数 | 描述 |
| --- | --- |
| `mlt.fl` | 指定应在其中识别感兴趣的术语以确定相似性的字段。该参数不适用于`MLTQParserPlugin`。 |
| `mlt.qf` | 指定用于确定相似文档的查询字段。这些字段也必须在`mlt.fl`参数中指定。字段名后面可以跟一个字符运算符(`^`)和相应的 boost。 |
| `boost` | 如果该参数设置为`true`，查询中感兴趣的术语将被提升。此参数不适用于`MLTQParserPlugin`。 |
| `mlt.mintf` | 指定最小术语频率。计数小于指定值的术语将从感兴趣术语列表中忽略。默认值为 2。 |
| `mlt.mindf` | 指定最小文档频率。出现在较少文档中的术语将被忽略。默认值为 5。 |
| `mlt.maxdf` | 指定最大文档频率。文档中出现超过指定值的术语将被忽略。 |
| `mlt.minwl` | 指定最小单词长度。长度较小的单词将被忽略。默认值为 0，编程为无效。 |
| `mlt.maxwl` | 指定最大单词长度。超过这个长度的单词将被忽略。默认值为 0，编程为无效。 |
| `mlt.maxqt` | 指定在形成查询的第二阶段要使用的最大术语数。默认值为 25。 |
| `mlt.maxntp` | 如果禁用了术语 vector，此参数将指定为每个存储字段解析的最大令牌数。默认值为 5000。 |

Note

在 Solr 5.3 之前，`MLTQParserPlugin`不支持这些通用参数。在`MLTQParserPlugin`中，参数不应以`mlt.`为前缀。

#### MoreLikeThisComponent

如果将`MoreLikeThisComponent`配置为任何处理程序，它将为主查询返回的每个文档返回相似的文档。该操作的执行成本很高，而且用户不太可能希望主查询的所有结果都是相似的文档。它适用于指纹识别和重复检测等场景，用于处理一批文档。表 [9-20](#Tab20) 表示通用参数。

表 9-20。

MoreLikeThisComponent Specific Parameters

<colgroup><col> <col></colgroup> 
| 参数 | 描述 |
| --- | --- |
| `mlt` | 如果设置为`true`，该布尔参数启用`MoreLikeThis`组件。默认情况下，它被设置为`false`。 |
| `mlt.count` | 为主查询的每个结果指定要返回的相似文档的数量。默认值为 5。 |

##### 它是如何工作的

下面是`MoreLikeThisComponent`处理请求所遵循的步骤:

The client requests a `SearchHandler` that has `MoreLikeThisComponent` registered to it. The handler invokes the `MoreLikeThisComponent`.   The `MoreLikeThisComponent` does no processing in the prepare phase.   In the process phase, all the matching documents retrieved by the main query are provided to `MoreLikeThisHelper` for retrieving similar documents.   This helper class creates a new `Query` object by extracting the interesting terms from the documents and executes it on index to retrieving similar documents. This process is followed for each document retrieved by the main query and so is costly to execute.   The retrieved documents are added to response and returned to the client.   Note

如果你对内部处理的细节感兴趣或者正在计划定制，可以参考这些步骤；否则 Solr 不要求你了解他们。

##### 用法

`MoreLikeThisComponent`是所有`SearchHandlers`的默认组件之一，因此不需要注册。以下是一个示例查询:

`$ curl ’` `http://localhost:8983/solr/hellosolr/select?q=apple`

`&mlt=true&mlt.fl=product&mlt.mindf=5&mlt.mintf=3&fl=product’`

#### 莫雷利克·蒂申德勒

`MoreLikeThisHandler`是 Solr 为查找相似文档提供的专用处理程序。与`MoreLikeThisComponent`不同，处理程序将返回与请求中指定的文档相似的文档。这是使用`MoreLikeThis`的首选方法，可以在用户预览文档时调用。您可以通过提供查询或`ContentStream`来找到类似的文档。该处理程序支持常用参数，如`fq`、`defType`和`facets`。除了通用的`MoreLikeThis`参数，表 [9-21](#Tab21) 提到了`MoreLikeThisHandler`支持的附加参数。

表 9-21。

MoreLikeThisHandlerSpecific Parameters

<colgroup><col> <col></colgroup> 
| 参数 | 描述 |
| --- | --- |
| `mlt.match.include` | 此布尔参数指定响应中是否应该包含匹配的文档。默认值为`true`。它仅适用于使用查询查找相似文档的情况。 |
| `mlt.match.offset` | 指定为响应主查询而返回的文档的偏移量，应该为该偏移量检索相似的文档。它仅适用于使用查询查找相似文档的情况。 |
| `mlt.interestingTerms` | 指定如何在响应中返回感兴趣的术语。Solr 支持三种风格的有趣术语:`none`:禁用该特性。这是默认值。`list`:以列表形式显示术语`details`:显示术语及其提升。 |

##### 它是如何工作的

下面是`MoreLikeThisHandler`处理请求所遵循的步骤:

`MoreLikeThisHandler` accepts either a content stream or a query.   If a query is provided, the handler parses it by using a defined query parser and forms a Solr `Query` object. If a content stream is provided, it creates a `Reader` object.   Solr runs the query, if applicable, on the index and retrieves matching document IDs but considers only the first retrieved document for `MoreLikeThis` matching.   The document ID or the reader is provided to `MoreLikeThisHelper` for retrieving similar documents.   This helper class creates a new `Query` object by extracting the interesting terms from the document or content stream and executes it on index to retrieve the matching documents.   The retrieved documents are added to the response, as well as the interesting terms and facets if specified.   The generated response is returned to the client.   Note

如果你对内部处理的细节感兴趣或者正在计划定制，可以参考这些步骤；否则 Solr 不要求你了解他们。

##### 使用

使用`MoreLikeThis`处理程序很容易。以下是步骤:

Define `MoreLikeThisHandler` in `solrconfig.xml`. `<requestHandler name="/mlt" class="solr.MoreLikeThisHandler" />`   Query for `MoreLikeThis` documents. Find documents similar to document with id APL_1001 `$ curl "` `http://localhost:8983/solr/mlt?q=id:APL_1001` `&mlt.fl=product&mlt.mintf=2&mlt.mindf=5"`  

#### MLTQParserPlugin

`MLTQParserPlugin`是查询解析器的工厂，它允许您检索与查询中指定的文档相似的文档。该条款允许您启用高亮显示和分页，可以在`q`、`fq`或`bq`中提及。解析器期望文档的`uniqueKey`作为一个值，不支持 Lucene 内部文档 ID 或任何任意查询。

从 Solr 5.3 开始，这个解析器支持除了`fl`和`boost`之外的所有通用参数。参数名不应以`mlt`为前缀。

##### 它是如何工作的

下面是 Solr 使用`MLTQParserPlugin`解析查询的步骤:

The parser creates a query by using the document ID provided and retrieves the matching document. If document with the specified ID doesn’t exist, Solr will report an exception.   For the retrieved document, Solr extracts the vector and term frequency of all the terms in the field list.   Using the terms and frequency, it filters out unnecessary terms and creates a `PriorityQueue`.   Finally, it creates `MoreLikeThisQuery` from terms in `PriorityQueue`.   Note

如果你对内部处理的细节感兴趣或者正在计划定制，可以参考这些步骤；否则 Solr 不要求你了解他们。

##### 使用

`MLTQParserPlugin`不需要`solrconfig.xml`中的任何定义。`UniqueKey`字段的值应该作为文档标识符提供。解析器的用法如下。必须指定至少一个`qf`字段。以下是一个查询示例:

`$ curl "``http://localhost:8983/solr/hellosolr/select`T2】

`q={!mlt qf=product mintf=2 mindf=5 maxdf=100}APL_1001"`

## 摘要

本章详细介绍了以下 Solr 特性:赞助搜索、拼写检查、自动完成和文档相似性。您了解了获得这些特性的方法，以及如何调整配置来定制和控制结果的行为。

在下一章中，您将学习各种扩展 Solr 的方法，包括 SolrCloud 模式。您将看到是什么使 Solr 成为高度可伸缩的分布式搜索引擎，以及如何在您的环境中设置它。